{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "743d17d8-d3f7-4d32-a32f-36516d83d9ce",
   "metadata": {},
   "source": [
    "# Sentyment analysis con BERT transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcf29f5-4176-41fc-aad7-af63cce80552",
   "metadata": {},
   "source": [
    "Carichiamo il BERT Tokenizer e Sequence Classifier pre-addestrati, così come InputExample e InputFeatures. Poi, costruiremo il nostro modello con il Sequence Classifier e il nostro tokenizer con il Tokenizer del BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb4f080a-2fb5-4ccd-845b-d2464e1720aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1decafb0-2683-49f7-b6f1-b43b9b0bb11a",
   "metadata": {},
   "source": [
    "Vediamo il nostro modello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20625f7-22e3-425b-9cdd-4ddfeae07f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 109,483,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee750f43-2624-47a0-960d-796f47eb15a3",
   "metadata": {},
   "source": [
    "Possiamo decidere di lasciarlo allenare tutto o di allenare solo il classificatore finale. \n",
    "Più layer rimarranno sbloccati, maggior memoria verrà occupata (CPU o GPU) e maggior tempo servirà per un epoca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4e1aa3-c410-4c3a-8e5a-e99413d212af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert (TFBertMainLayer)       multiple                  109482240 \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           multiple                  1538      \n",
      "=================================================================\n",
      "Total params: 109,483,778\n",
      "Trainable params: 1,538\n",
      "Non-trainable params: 109,482,240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for lay in model.layers:\n",
    "    if lay.name != 'classifier':\n",
    "        lay.trainable=False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d7547b-e473-4819-9576-6ddd01c4f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f1271-fbbc-4205-bfe4-19c8e8f077d5",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168724d1-fca6-4087-a9a6-eebc2c20915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('../data/Reviews.csv', usecols=['Text', 'Summary', 'Score'])\n",
    "df.head()\n",
    "df = df[df['Score'] != 3]\n",
    "df['Sentiment'] = df['Score'].apply(lambda rating : 1 if rating > 3 else 0)\n",
    "df=df.sample(2500).reset_index() #subset per rendere il tutorial più veloce\n",
    "index = df.index\n",
    "\n",
    "df['random_number'] = np.random.randn(len(index))\n",
    "\n",
    "train_full = df[df['random_number'] <= 0.8]\n",
    "test_full = df[df['random_number'] > 0.8]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e1475-95e4-4d7a-a111-a3a592126a83",
   "metadata": {},
   "source": [
    "A differenza dei modelli basati su bag of words, ora possiamo usare la colonna del testo, e non quella del riassunto, perché invece di avere una rappresentazione sparsa delle frequenze abbiamo un vettore di lunghezza fissa costruito usando i \"token\", parti di parola. Si potrebbe valutare se sia meglio l'uno, l'altro o la somma dei due."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6e42b54-e7ee-4e32-a97b-f3f9afe062a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA_COLUMN</th>\n",
       "      <th>LABEL_COLUMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My mom and I bought these some years back, fro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>These tasty shrimp crackers remind me of homet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I got this tea because it is supposed to help ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I received the pack of three flavors today and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I use this for cooking rice, veggies, soups, e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DATA_COLUMN  LABEL_COLUMN\n",
       "0  My mom and I bought these some years back, fro...             1\n",
       "1  These tasty shrimp crackers remind me of homet...             1\n",
       "2  I got this tea because it is supposed to help ...             1\n",
       "3  I received the pack of three flavors today and...             1\n",
       "4  I use this for cooking rice, veggies, soups, e...             1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train = train_full.filter(['Text', 'Sentiment']).reset_index(drop=True)\n",
    "train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f98118e-ff0c-4b0e-9c69-aa250eacd552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA_COLUMN</th>\n",
       "      <th>LABEL_COLUMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These crackers are my new favorite. The Parmes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have an 8 year old and a 2 year old. They ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Me and my kids are loving the aerogarden.  The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To be honest I wish I had more to say about th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excellent product and delivered fresh. Made of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         DATA_COLUMN  LABEL_COLUMN\n",
       "0  These crackers are my new favorite. The Parmes...             1\n",
       "1  I have an 8 year old and a 2 year old. They ar...             1\n",
       "2  Me and my kids are loving the aerogarden.  The...             1\n",
       "3  To be honest I wish I had more to say about th...             1\n",
       "4  Excellent product and delivered fresh. Made of...             1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test = test_full.filter(['Text', 'Sentiment']).reset_index(drop=True)\n",
    "test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ebe5c-417e-4933-bc74-42aee92c8192",
   "metadata": {},
   "source": [
    "## Creazione di sequenze di ingresso\n",
    "Abbiamo due oggetti Dataframe di pandas che ci aspettano per convertirli in oggetti adatti al modello BERT. Sfrutteremo la funzione InputExample che ci aiuta a creare sequenze dal nostro set di dati. La funzione InputExample può essere chiamata come segue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7f3b669-6f5a-4e85-9581-433de423754d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputExample(guid=None, text_a='Hello, world', text_b=None, label=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "InputExample(guid=None,\n",
    "             text_a = \"Hello, world\",\n",
    "             text_b = None,\n",
    "             label = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1930d8-a71b-4527-bb9a-d7b379ca2ab8",
   "metadata": {},
   "source": [
    "## Ora creeremo due funzioni principali:\n",
    "\n",
    "    1 - convert_data_to_examples: Questa accetterà i nostri dataset di training e test e convertirà ogni riga in un oggetto InputExample.\n",
    "    2 - convert_examples_to_tf_dataset: Questa funzione tokenizzerà gli oggetti InputExample, poi creerà il formato di input richiesto con gli oggetti tokenizzati, infine, creerà un dataset di input che possiamo dare in pasto al modello.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca83caf9-1d89-4c07-b9a9-43f91a5b003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
    "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "  \n",
    "  return train_InputExamples, validation_InputExamples\n",
    "\n",
    "  train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
    "                                                                           test, \n",
    "                                                                           'DATA_COLUMN', \n",
    "                                                                           'LABEL_COLUMN')\n",
    "  \n",
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'DATA_COLUMN'\n",
    "LABEL_COLUMN = 'LABEL_COLUMN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3af245-08db-470e-81b1-cce5b9bce36c",
   "metadata": {},
   "source": [
    "We can call the functions we created above with the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81bc0058-3d0e-4567-ad27-d6007bedfc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Egon\\anaconda3\\envs\\bert\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(16)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6b21d2-6087-4b44-bc70-1c6787810c66",
   "metadata": {},
   "source": [
    "Il nostro set di dati contenente le sequenze di input elaborate è pronto per essere dato in pasto al modello.\n",
    "\n",
    "## Configurazione del modello BERT e fine-tuning\n",
    "\n",
    "Useremo Adam come ottimizzatore, CategoricalCrossentropy come funzione di perdita e SparseCategoricalAccuracy come metrica di precisione. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75b458c9-1921-4d51-ac01-758a093865ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:From C:\\Users\\Egon\\anaconda3\\envs\\bert\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "124/124 [==============================] - 128s 950ms/step - loss: 0.5107 - accuracy: 0.7923 - val_loss: 0.4322 - val_accuracy: 0.8391\n",
      "Epoch 2/2\n",
      "124/124 [==============================] - 116s 934ms/step - loss: 0.4440 - accuracy: 0.8367 - val_loss: 0.4289 - val_accuracy: 0.8430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e011825af0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.fit(train_data, epochs=2, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a09391-3832-4d33-837e-edbb0192a4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"These crackers are my new favorite. The Parmesan really is the best. The sharp cheddar that comes mixed in the box is really good, too. I used to think the white cheddar was the best. Now, it's an 'old reliable'. I keep wondering which of these flavors would be best crumbled in the food processor, or blender to be used in meatballs, or meatloaf. Cheez-Its, made into crumbs, would be good on baked, or fried chicken, or fish, or on top of your favorite casserole dish. Really, try these, they're delicious.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pred_sentences = [test['DATA_COLUMN'][0]]\n",
    "pred_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07a96c5d-e199-4f59-8618-ecc329a9b3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These crackers are my new favorite. The Parmesan really is the best. The sharp cheddar that comes mixed in the box is really good, too. I used to think the white cheddar was the best. Now, it's an 'old reliable'. I keep wondering which of these flavors would be best crumbled in the food processor, or blender to be used in meatballs, or meatloaf. Cheez-Its, made into crumbs, would be good on baked, or fried chicken, or fish, or on top of your favorite casserole dish. Really, try these, they're delicious. : \n",
      " Positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "labels = ['Negative','Positive']\n",
    "label = tf.argmax(tf_predictions, axis=1)\n",
    "label = label.numpy()\n",
    "for i in range(len(pred_sentences)):\n",
    "  print(pred_sentences[i], \": \\n\", labels[label[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820a6514-59e7-4df4-b9e6-7ed54f7e6d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
